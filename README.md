# BERT_vs_Transformer-XL

A Comparison of Two NLP Frameworks for General Research Purposes

The goal of Natural Language Processing (NLP) is to train computers to analyze human language. The widest-used versions of NLP are used in spell-check and grammar-check programs, but more advanced versions have been developed into tools used for much more than just identifying context within search queries. NLP is becoming increasingly more useful for researchers to summarize large amounts of data or long-form documents without the need for human supervision. Our project will examine two powerful NLP algorithms, BERT and Transformer-XL in their abilities to extract and summarize data from chosen pieces of literature. We will provide each algorithm with the same dataset and judge the results for each algorithm on its accuracy compared to its execution time.
